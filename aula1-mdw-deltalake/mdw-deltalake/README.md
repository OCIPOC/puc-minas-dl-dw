<p align="center">
  <a href="" rel="noopener">
 <img width=500px height=100px src="https://docs.delta.io/latest/_static/delta-lake-logo.png" alt="Project logo"></a>
</p>

<h3 align="center">Delta lake √© um projeto de c√≥digo aberto que permite construir uma arquitetura Lakehouse em cima de sistemas de armazenamento de dados, como S3, ADLS, GCS e HDFS.</h3>

<div align="center">

[![Status](https://img.shields.io/badge/status-active-success.svg)]()
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](/LICENSE)

</div>

---

## üìù Conte√∫do

- [Sobre](#about)
- [Arquitetura](#architeture)
- [Utiliza√ß√£o](#usage)
- [Como funciona](#built_using)

## üßê Sobre <a name = "about"></a>

## üîß Arquitetura MDW com Delta lake <a name = "architeture"></a>

![image](https://live-delta-io.pantheonsite.io/wp-content/uploads/2019/04/Delta-Lake-marketecture-0423c.png)


O Delta l√™ dados de um sistema de arquivos chamado landing-zone usando depend√™ncias deltalake, que s√£o pacotes jars que est√£o na configura√ß√£o de sess√£o do spark, com o qual √© poss√≠vel usar o framework delta lake. ap√≥s a execu√ß√£o dos script, os dados ser√£o escritos no diret√≥rio passado no c√≥digo, dentro da tabela delta ser√° gravado um diret√≥rio chamado _delta_log, que √© respons√°vel por armazenar os arquivos incrementais nos metadados da tabela, ser√° algo como
00000000000000000000.json, 0000000000000000000001.json...
O arquivo Json na pasta _delta_log ter√° as informa√ß√µes como adicionar/remover arquivos parquet (para Atomicidade), stats (para desempenho otimizado e salto de dados), partitionBy (para remo√ß√£o de parti√ß√£o), readVersions (para viagem no tempo), commitInfo (para auditoria) .

![image](https://miro.medium.com/max/1400/0*5XnRRdbrbuuNGFzJ.png)

l√™ os dados em formato delta, o que resulta em ganho de performance por ser armazenado em formato parquet e ter uma das grandes vantagens do gerenciamento de metadados _delta_log, s√£o realizadas etapas de processamento em que s√£o removidas colunas desnecess√°rias e prepara√ß√£o de tabelas com join para MDW modelagem com dados normalizados em formatos de conjunto de dados.

tem a responsabilidade de enriquecer os dados, neste processo √© onde tratamos os dados e refinamos para a √°rea de neg√≥cios ou quem ir√° consumir os dados, neste script deixei o exemplo de como utilizar a viagem no tempo utilizando par√¢metro passado em a fun√ß√£o que declaramos .option("versionAsOf", "0"), abaixo est√£o as imagens ap√≥s a ingest√£o


Este projeto visa fazer um processamento etl simples, usando pyspark com o framework Delta. O trabalho do pyspark consumir√° um sistema de arquivos intitulado landing-zone com arquivos no formato json. Usaremos algumas t√©cnicas de viagem no tempo, escrita em formato delta para controle de gerenciamento de tabelas e muito mais.

## üîß Upserts Delta Lake <a name = "deltalake"></a>

![image](https://i.ytimg.com/vi/R4f6SKOetB4/maxresdefault.jpg)

Como funciona a l√≥gica do Delta Lake Upserts e como podemos fazer a ado√ß√£o da nova e moderna Arquitetura Lake House, para isso disponibilizei um notebook jupyter, no qual lemos dados no formato json, que s√£o relacionados aos usu√°rios de um sistema. Nosso principal objetivo √© ler esses arquivos no formato Json e convert√™-los em uma Tabela Delta. Depois disso podemos acessar os metadados que s√£o gerados dentro de um diret√≥rio chamado _delta_log, que podemos acessar atrav√©s do m√©todo DeltaTable.forPath. Ap√≥s instanciar a Tabela Delta, conseguimos mesclar os novos dados usando whenMatchedUpdateAll usando a condi√ß√£o de que vamos comparar e finalmente atualizar nossa Tabela Delta.